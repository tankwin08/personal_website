{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tan Zhou","text":""},{"location":"#about-me","title":"About Me","text":"<p>Hello! I'm Tan Zhou, a Data Scientist and ML professional with over 8 years of experience in machine learning, Generative AI, and statistical modeling. Currently, I lead data science initiatives, where I developed innovative GenAI solutions\u2014like an enterprise HR bot and a document processor\u2014to drive efficiency and solve complex business challenges.</p> <p>With a Ph.D. in Applied Statistics from Texas A&amp;M University, I specialize in leveraging ML/DL, LLMs, and advanced analytics to transform data into actionable insights and drive business value and impact. My work spans industries, from Finanace (e.g. pricing systems, contract health), HR, and Operation (predictive maintenance) to geospatial analysis and sustainability dashboards. I'm passionate about building scalable AI solutions and collaborating with teams to deliver impact.</p>"},{"location":"#contact-location","title":"Contact &amp; Location","text":"<ul> <li>Location: St. Louis, MO</li> <li>Email: tankchow12@gmail.com</li> </ul>"},{"location":"about/","title":"About Me","text":""},{"location":"about/#professional-background","title":"Professional Background","text":"<p>I am a Senior Data Scientist with 8+ years of experience in both industry and academia. My work focuses on developing innovative solutions using quantitative and machine learning models for complex business problems.</p>"},{"location":"about/#areas-of-expertise","title":"Areas of Expertise","text":"<ul> <li>Machine Learning &amp; AI</li> <li>Statistical Analysis</li> <li>Time Series Analysis</li> <li>Natural Language Processing</li> <li>Computer Vision</li> <li>Remote Sensing</li> <li>Big Data Processing</li> <li>Geospatial Data Engineering</li> </ul>"},{"location":"about/#academic-background","title":"Academic Background","text":"<ul> <li>Ph.D. in Applied Statistics and Geo-computation from Texas A&amp;M University</li> <li>Focus on signal processing, Bayesian methods, and Machine learning</li> <li>Research expertise in LiDAR data processing and analysis</li> </ul>"},{"location":"about/#current-work-focus","title":"Current Work Focus","text":"<ul> <li>Developing machine learning solutions for business optimization</li> <li>Algorithm development and implementation</li> <li>Processing and analyzing various data types:</li> <li>Time series data</li> <li>Text and NLP</li> <li>Geospatial data</li> <li>Remote sensing data</li> </ul>"},{"location":"about/#industry-experience","title":"Industry Experience","text":"<p>Experience spans across: - University research - Non-government organizations - Start-ups - Private sector enterprises</p>"},{"location":"about/#research-interests","title":"Research Interests","text":"<ul> <li>Signal Processing</li> <li>Bayesian Methods</li> <li>Machine Learning Applications</li> <li>Remote Sensing</li> <li>Environmental Data Analysis</li> </ul>"},{"location":"education/","title":"Education","text":""},{"location":"education/#phd-in-applied-statistics-and-geo-computation","title":"Ph.D. in Applied Statistics and Geo-computation","text":"<p>Texas A&amp;M University | 2013 - 2017 - Focus: Signal processing, Bayesian and Machine learning - Research: LiDAR data processing and analysis - Publications in remote sensing and machine learning applications</p>"},{"location":"education/#ms-in-environmental-science","title":"M.S. in Environmental Science","text":"<p>Beijing Normal University | 2011 - 2013 - Focus: Environment Science analysis and modeling - Research: Environmental data analysis</p>"},{"location":"experience/","title":"Experience","text":""},{"location":"experience/#data-science-manager","title":"Data Science Manager","text":"<p>Equinix, remote |  Jan 2024 - present</p> <p>Led enterprise HR bot development: Design and Enhanced GenAI based UX through design improvements, integrated Azure AI search, and optimized data ingestion, driving significant productivity gains and reducing HR support costs.</p> <p>Developed EIDP (GenAI-powered document processor): Automated extraction, analysis, summarization, and translation of diverse documents, streamlining processes across Equinix departments and boosting accuracy and efficiency.</p> <p>Built contract health monitoring overhaul: Leveraged GenAI to conduct contract analysis and comparison, cutting review time and costs while delivering actionable insights for risk management.</p>"},{"location":"experience/#lead-ml-engineer-lead-ds","title":"Lead ML Engineer/ Lead DS","text":"<p>Equinix, remote | Sep 2021 - Dec 2023</p> <p>Led B2B Intelligent Price Recommendations: Built AI/ML-driven pricing models for renewals and new deals with explainable AI, cutting manual effort, scaling operations, and increasing user trust &amp; understanding.</p> <p>Developed audio-based predictive maintenance system: Employed ML/ DL(CNN) to analyze audio data from IBX, enhancing safety by predicting failures, reducing downtime for improved productivity and customer experience.</p> <p>Designed and led sustainability dashboard development: Utilized ETS time series models to forecast carbon footprint, delivering insights for emission reduction targets, supporting climate neutrality commitment</p>"},{"location":"experience/#senior-data-scientist","title":"Senior Data Scientist","text":"<p>Colaberry/Bayer Crop Science - St. Louis | July2018 - Agu 2021</p> <p>Built automated data pipeline and processing framework: Developed a PySpark-based system to process large geospatial data (e.g., Sentinel-2), applying ML (RF, Bayesian) methods to estimate soil attributes with uncertainty, and support field operation.</p> <p>Enhanced yield prediction with ML and sentiment analysis: Combined machine learning and SWIVEL pretrained embeddings to forecast and synchronize crop yields during the growing season, improving planning accuracy.</p> <p>Analyzed GET interactions for crop yield prediction: Built a framework to evaluate genetic, environmental, and treatment (e.g., seed rate) effects, enabling outcome-based pricing insights and crop hybrid optimization.</p>"},{"location":"experience/#postdoctoral-research-associate","title":"Postdoctoral Research Associate","text":"<p>Texas A&amp;M University | Jan 2018 - July 2018</p> <ul> <li>Developed validation plan for upcoming ICESat-2 data</li> <li>Developed algorithms for waveform LiDAR visualization and R package</li> <li>Predicted corn and sorghum yield with UAV-acquired data</li> </ul> <p>[Additional experience details...]</p>"},{"location":"skills/","title":"Skills","text":""},{"location":"skills/#languages-operating-systems-tools","title":"Languages, Operating Systems &amp; Tools","text":"<ul> <li>Python, R, SQL, JavaSCript, HTML, CSS</li> <li>git, linux, bash, Docker, Kubernetes</li> <li>GCP, AZURE (LLM based services), AWS, Pyspark</li> </ul>"},{"location":"skills/#genai","title":"GenAI","text":"<ul> <li>Langchain</li> <li>AZURE OpenAI, Azure Form Recognizer, Google Vertex AI</li> <li>Ollama, Deepseek, OpenCV</li> <li>RAG, Fine-tuning, Prompt Engineering, LLMs, AgentAI, deep research</li> </ul>"},{"location":"skills/#data-science","title":"Data Science","text":"<ul> <li>Data Cleaning</li> <li>Data Visualization</li> <li>Data Wrangling</li> <li>Data Analysis/modelling</li> </ul>"},{"location":"skills/#machine-learning","title":"Machine Learning","text":"<ul> <li>Bayesian</li> <li>Random Forest</li> <li>Neural Network &amp; Deep Learning (CNN, ResNet, UNet, LSTM, transfer learning)</li> <li>Decision Tree</li> <li>Nearest Neighbor</li> <li>Support Vector Machine</li> <li>Recommender System</li> <li>Natural Language Processing</li> </ul>"},{"location":"skills/#statistical-methods","title":"Statistical Methods","text":"<ul> <li>Partial Least Square Regression</li> <li>Univariate and Multivariate Regression</li> <li>Linear Discriminant Analysis</li> <li>Logistic Regression</li> <li>Time Series Analysis</li> <li>Factor Analysis</li> <li>Mixed Effect Modeling</li> </ul>"},{"location":"projects/","title":"Projects Overview","text":"<p>My work spans across various domains of data science and machine learning, including:</p> <pre><code>- GenAI\n- Machine Learning and Deep Learning Applications\n- Natural Language Processing\n- Time Series Analysis\n- Computer Vision\n- LiDAR Data Processing\n</code></pre>"},{"location":"projects/contributions/","title":"Open Source Contributions","text":""},{"location":"projects/contributions/#lidar-data-processing-analysis","title":"LiDAR Data Processing &amp; Analysis","text":""},{"location":"projects/contributions/#waveformlidar-r-package","title":"Waveformlidar R Package","text":"<p>An R package dedicated to Full Waveform (FW) LiDAR data processing, analysis, and visualization. Provides tools for waveform decomposition, metrics extraction, and point cloud generation.</p> <p>Learn More</p>"},{"location":"projects/contributions/#tree-segmentation-algorithm-not-finised","title":"Tree Segmentation Algorithm (not finised)","text":"<p>Developed advanced algorithms for individual tree detection and segmentation using LiDAR point cloud data, incorporating machine learning techniques for improved accuracy.</p> <p>Learn More</p>"},{"location":"projects/contributions/tree_segmentation/","title":"Tree Segmentation Algorithm","text":""},{"location":"projects/contributions/tree_segmentation/#overview","title":"Overview","text":"<p>Advanced algorithm development for individual tree detection and segmentation using LiDAR point cloud data.</p>"},{"location":"projects/contributions/tree_segmentation/#technologies","title":"Technologies","text":"<ul> <li>R Programming</li> <li>Point Cloud Processing</li> <li>Machine Learning</li> <li>Spatial Analysis</li> </ul>"},{"location":"projects/contributions/tree_segmentation/#key-features","title":"Key Features","text":"<ul> <li>Automated tree detection</li> <li>Crown delineation</li> <li>Height estimation</li> <li>Biomass calculation</li> <li>Species classification</li> </ul>"},{"location":"projects/contributions/tree_segmentation/#results","title":"Results","text":"<ul> <li>Improved detection accuracy</li> <li>Reduced processing time</li> <li>Enhanced crown delineation</li> <li>Better species differentiation</li> </ul>"},{"location":"projects/contributions/tree_segmentation/#applications","title":"Applications","text":"<ul> <li>Forest inventory</li> <li>Urban tree mapping</li> <li>Ecological monitoring</li> <li>Forest management</li> </ul>"},{"location":"projects/contributions/waveformlidar_r_package/","title":"Waveformlidar R Package","text":"<p> Project link: https://github.com/tankwin08/waveformlidar</p>"},{"location":"projects/contributions/waveformlidar_r_package/#overview","title":"Overview","text":"<p>An open-source R package for processing waveform lidar data and exemplifying their uses in vegetation structure analysis.</p>"},{"location":"projects/contributions/waveformlidar_r_package/#key-features","title":"Key Features","text":"<ul> <li>Gaussian, adaptive Gaussian, and Weibull decompositions</li> <li>Deconvolution approaches (Gold and Richard-Lucy)</li> <li>Waveform metrics extraction</li> <li>Hyper Point Cloud (HPC) generation</li> <li>3D voxelization capabilities</li> <li>Composite waveform generation</li> </ul>"},{"location":"projects/contributions/waveformlidar_r_package/#applications","title":"Applications","text":"<ul> <li>Forest structure analysis</li> <li>Vegetation mapping</li> <li>Biomass estimation</li> <li>Ecological monitoring</li> <li>Environmental assessment</li> </ul>"},{"location":"projects/contributions/waveformlidar_r_package/#impact","title":"Impact","text":"<ul> <li>Simplified waveform processing workflow</li> <li>Enhanced data visualization</li> <li>Improved analysis capabilities</li> <li>Integration with existing LiDAR tools</li> </ul> <p>GitHub Repository</p>"},{"location":"projects/creations/","title":"Professional Projects","text":""},{"location":"projects/creations/#recent-projects","title":"Recent Projects","text":""},{"location":"projects/creations/#generative-ai-solutions","title":"Generative AI Solutions","text":"<ul> <li>Enterprise HR Chatbot Development</li> <li>Intelligent Document Processing System</li> <li>ML-Driven Predictive Maintenance</li> <li>Sustainability Analytics Dashboard</li> </ul>"},{"location":"projects/creations/#machine-learning-applications","title":"Machine Learning Applications","text":"<ul> <li>Sentimental Analysis</li> <li>Enhanced Fraud Detection</li> <li>Time Series Analysis</li> </ul>"},{"location":"projects/creations/#deep-learning-advanced-analytics","title":"Deep Learning &amp; Advanced Analytics","text":"<ul> <li>Bayesian LSTM</li> <li>NLP SWIVEL</li> <li>Ensemble Models</li> <li>Bayesian Neural Networks</li> </ul>"},{"location":"projects/creations/bayesian_lstm/","title":"Bayesian LSTM for Time Series Prediction","text":""},{"location":"projects/creations/bayesian_lstm/#overview","title":"Overview","text":"<p>Implemented a Bayesian LSTM model for time series forecasting with uncertainty quantification, providing probabilistic predictions for business metrics.</p>"},{"location":"projects/creations/bayesian_lstm/#technologies","title":"Technologies","text":"<ul> <li>PyTorch</li> <li>Bayesian Neural Networks</li> <li>LSTM Architecture</li> <li>Probabilistic Programming</li> <li>Time Series Analysis</li> </ul>"},{"location":"projects/creations/bayesian_lstm/#key-features","title":"Key Features","text":"<ul> <li>Uncertainty estimation</li> <li>Automatic hyperparameter tuning</li> <li>Multi-step forecasting</li> <li>Anomaly detection</li> <li>Dynamic learning rate adjustment</li> </ul>"},{"location":"projects/creations/bayesian_lstm/#results","title":"Results","text":"<ul> <li>20% improvement in prediction accuracy</li> <li>Reliable uncertainty bounds</li> <li>Robust performance on multiple datasets</li> </ul>"},{"location":"projects/creations/bayesian_nn/","title":"Bayesian Neural Networks","text":""},{"location":"projects/creations/bayesian_nn/#overview","title":"Overview","text":"<p>Implemented Bayesian Neural Networks for probabilistic deep learning, providing uncertainty estimates in predictions.</p>"},{"location":"projects/creations/bayesian_nn/#technologies","title":"Technologies","text":"<ul> <li>PyMC3</li> <li>TensorFlow Probability</li> <li>Probabilistic Programming</li> <li>Deep Learning</li> </ul>"},{"location":"projects/creations/bayesian_nn/#key-features","title":"Key Features","text":"<ul> <li>Uncertainty quantification</li> <li>Posterior distribution estimation</li> <li>Variational inference</li> <li>Model averaging</li> <li>Active learning integration</li> </ul>"},{"location":"projects/creations/bayesian_nn/#applications","title":"Applications","text":"<ul> <li>Risk assessment</li> <li>Decision making under uncertainty</li> <li>Anomaly detection</li> <li>Predictive maintenance</li> </ul>"},{"location":"projects/creations/enhanced_fraud_detection/","title":"Enhanced Fraud Detection System","text":"<p> Project link</p>"},{"location":"projects/creations/enhanced_fraud_detection/#overview","title":"Overview","text":"<p>Developed a scalable fraud detection system using PySpark to handle large-scale transaction data and identify fraudulent activities in real-time.</p>"},{"location":"projects/creations/enhanced_fraud_detection/#technologies","title":"Technologies","text":"<ul> <li>PySpark MLlib</li> <li>Distributed Computing</li> <li>Machine Learning Pipeline</li> <li>Real-time Processing</li> </ul>"},{"location":"projects/creations/enhanced_fraud_detection/#key-features","title":"Key Features","text":"<ul> <li>Automated feature engineering</li> <li>Imbalanced data handling</li> <li>Real-time prediction capabilities</li> <li>Scalable processing pipeline</li> <li>Model performance monitoring</li> </ul>"},{"location":"projects/creations/enhanced_fraud_detection/#results","title":"Results","text":"<ul> <li>Reduced false positives by 30%</li> <li>Improved detection rate by 25%</li> <li>Processing capability of 1M+ transactions/hour</li> </ul>"},{"location":"projects/creations/enhanced_fraud_detection/#goal","title":"Goal","text":"<p>To examplify the feature selection strategy in PySpark and furhter enhanc the pyspark pipeline\u2019s performance on fraud detection.</p> <p>In this project, I will continue to work on the data from the project fradu_detection_ML_PySpark. The data exploration will be same, and the feature selction will use input perturbation strtegry instead of PCA as I did in the previous project.</p>"},{"location":"projects/creations/enhanced_fraud_detection/#why-feature-selection","title":"Why feature selection?","text":"<ol> <li>Curse of dimensionality \u2014 Overfitting</li> </ol> <p>The common theme of the problems is that when the dimensionality increases, the volume of the space increases so fast that the available data become sparse. This sparsity is problematic for any method that requires statistical significance.</p> <p>In order to obtain a statistically sound and reliable result, the amount of data needed to support the result often grows exponentially with the dimensionality.</p> <p>Also, organizing and searching data often relies on detecting areas where objects form groups with similar properties; in high dimensional data, however, all objects appear to be sparse and dissimilar in many ways, which prevents common data organization strategies from being efficient.</p> <ol> <li>Occam\u2019s Razor</li> </ol> <p>We want our models to be simple and explainable. We lose explainability when we have a lot of features.</p> <p>3 Noise in the data</p> <p>In real applications, the data are not perfect and always noisy inherently.</p> <p>Commonly used methods for feature selection In summary, there are several commonly used methods to conduct feature selction in data preprocessing.</p> <p>1 Correlation or chi-square</p> <p>Chose the top-n high correlated variables or high chi-squre variables with respective to target variables. The intuition is that if a feature is independent to the target, it will not be useful or uninformative for target classification or regression.</p> <p>2 Stepwise method</p> <p>This is a wrapper based method. The goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.</p> <p>3 Lasso - Penalized likelihood</p> <p>LASSO models have been used extensively in high-dimensional model selection problems, that is when the number of IVs \ud835\udc58 by far exceeds the sample size \ud835\udc5b.</p> <p>Regression coefficients estimated by the LASSO are biased by intention, but can have smaller mean squared error (MSE) than conventional estimates. It prefer to have fewer variales with huge contribution to the target.</p> <p>Because of the bias, their interpretation in explanatory or descriptive models is difficult, and confidence intervals based on resampling procedures such as the percentile bootstrap do not reach their claimed nominal level. Another problem with LASSO estimation is its dependence on the scale of the covariates</p> <p>4 PCA</p> <p>PCA is a commonly used as dimension reduction technique by projecting each data point onto only the first few principal components to obtain lower-dimensional data while preserving as much of the data\u2019s variation as possible.</p> <p>The advantages of PCA:</p> <p>Removes Correlated Features Improves Algorithm Performance Reduces Overfitting Improves Visualization The things we need to consider before using PCA:</p> <p>Independent variables become less interpretable: Data standardization is must before PCA: pca is affected by scale Information loss 5 Input Perturbation</p> <p>This algorithm was introduced by Breiman in his seminal paper on random forests. Although he presented this algorithm in conjunction with random forests, it is model-independent and appropriate for any supervised learning model.</p> <p>This algorithm, known as the input perturbation algorithm, works by evaluating a trained model\u2019s accuracy with each of the inputs individually shuffled from a data set. Shuffling an input causes it to become useless\u2014effectively removing it from the model. More important inputs will produce a less accurate score when they are removed by shuffling them. This process makes sense, because important features will contribute to the accuracy of the model.</p>"},{"location":"projects/creations/ensemble_models/","title":"Advanced Ensemble Learning Models","text":""},{"location":"projects/creations/ensemble_models/#overview","title":"Overview","text":"<p>Developed sophisticated ensemble learning models combining multiple algorithms for improved prediction accuracy and robustness.</p>"},{"location":"projects/creations/ensemble_models/#technologies","title":"Technologies","text":"<ul> <li>Scikit-learn</li> <li>XGBoost</li> <li>LightGBM</li> <li>CatBoost</li> <li>Stacking/Blending techniques</li> </ul>"},{"location":"projects/creations/ensemble_models/#key-features","title":"Key Features","text":"<ul> <li>Model stacking</li> <li>Cross-validation</li> <li>Feature importance analysis</li> <li>Automated model selection</li> <li>Hyperparameter optimization</li> </ul>"},{"location":"projects/creations/ensemble_models/#results","title":"Results","text":"<ul> <li>15% accuracy improvement</li> <li>Enhanced model robustness</li> <li>Reduced overfitting</li> </ul>"},{"location":"projects/creations/intelligent_document_processing_system.md/","title":"Intelligent Document Processing System","text":"<p>Project link</p>"},{"location":"projects/creations/intelligent_document_processing_system.md/#overview","title":"Overview","text":"<p>The Intelligent Document Processing System is a powerful application that leverages cutting-edge generative AI techniques to extract, analyze, and interact with information from various document types. This system transforms the way organizations handle document-based information by enabling natural language queries against document content.</p> <p></p>"},{"location":"projects/creations/intelligent_document_processing_system.md/#key-features","title":"Key Features","text":"<ul> <li>Multi-format Document Support: Process PDFs, Word documents, text files, CSVs, PowerPoint presentations, and even images</li> <li>Interactive Question-Answering: Ask natural language questions about document content</li> <li>Batch Processing: Run multiple queries against document sets simultaneously</li> <li>Flexible Model Selection: Choose from various LLM models based on specific needs</li> </ul>"},{"location":"projects/creations/intelligent_document_processing_system.md/#generative-ai-techniques-implemented","title":"Generative AI Techniques Implemented","text":""},{"location":"projects/creations/intelligent_document_processing_system.md/#retrieval-augmented-generation-rag","title":"Retrieval Augmented Generation (RAG)","text":"<p>At the core of our system is the RAG architecture, which combines the power of retrieval-based and generative approaches:</p> <ol> <li>Document Chunking &amp; Embedding: Documents are split into semantic chunks and transformed into vector embeddings using Ollama's embedding models</li> <li>Similarity-Based Retrieval: When a query is received, the system identifies the most relevant document sections using similarity search with threshold filtering</li> <li>Context-Aware Generation: The retrieved context is fed to a large language model along with the query to generate accurate, contextually relevant responses</li> </ol>"},{"location":"projects/creations/intelligent_document_processing_system.md/#advanced-prompt-engineering","title":"Advanced Prompt Engineering","text":"<p>The system employs sophisticated prompt templates that:</p> <ul> <li>Instruct the model to focus only on information present in the documents</li> <li>Provide clear instructions for handling cases where information isn't available</li> <li>Structure the context and question format for optimal model comprehension</li> </ul>"},{"location":"projects/creations/intelligent_document_processing_system.md/#vector-store-optimization","title":"Vector Store Optimization","text":"<p>Our implementation includes:</p> <ul> <li>Similarity Score Thresholding: Only returns documents above a relevance threshold</li> <li>Fetch-K Optimization: Retrieves a larger initial candidate set before filtering</li> <li>Optimized K-Parameter: Fine-tuned for the ideal balance between comprehensive context and focused responses</li> </ul>"},{"location":"projects/creations/intelligent_document_processing_system.md/#technical-implementation","title":"Technical Implementation","text":"<p>The system is built using:</p> <ul> <li>LangChain: For document processing, embedding, and retrieval pipelines</li> <li>Ollama: For local deployment of powerful LLMs like Deepseek</li> <li>Streamlit: For an intuitive, user-friendly interface</li> </ul>"},{"location":"projects/creations/intelligent_document_processing_system.md/#business-impact","title":"Business Impact","text":"<p>This intelligent document processing system delivers significant value by:</p> <ul> <li>Reducing time spent searching through documents by up to 70%</li> <li>Enabling natural language interaction with document repositories</li> <li>Providing accurate, contextual responses based on document content</li> <li>Supporting decision-making with rapid information retrieval</li> </ul>"},{"location":"projects/creations/intelligent_document_processing_system.md/#future-enhancements","title":"Future Enhancements","text":"<p>We're continuously improving the system with plans to add:</p> <ul> <li>Multi-modal document understanding (images within documents)</li> <li>Custom fine-tuning options for domain-specific applications</li> <li>Enhanced metadata filtering and search</li> </ul> <p>This project demonstrates the practical application of generative AI techniques to solve real-world document processing challenges, creating a powerful tool for knowledge extraction and information retrieval.</p>"},{"location":"projects/creations/nlp_swivel/","title":"NLP SWIVEL Implementation","text":""},{"location":"projects/creations/nlp_swivel/#overview","title":"Overview","text":"<p>Implemented SWIVEL (Submatrix-wise Vector Embedding Learner) for efficient word embedding generation, optimizing for large-scale text processing.</p>"},{"location":"projects/creations/nlp_swivel/#technologies","title":"Technologies","text":"<ul> <li>TensorFlow</li> <li>Natural Language Processing</li> <li>Distributed Computing</li> <li>Word Embeddings</li> </ul>"},{"location":"projects/creations/nlp_swivel/#key-features","title":"Key Features","text":"<ul> <li>Efficient matrix factorization</li> <li>Scalable word embedding</li> <li>Contextual similarity analysis</li> <li>Memory-efficient processing</li> <li>Multi-language support</li> </ul>"},{"location":"projects/creations/nlp_swivel/#applications","title":"Applications","text":"<ul> <li>Document classification</li> <li>Semantic similarity analysis</li> <li>Content recommendation</li> <li>Language modeling</li> </ul>"},{"location":"projects/creations/sentimental_analysis/","title":"Airline Sentiment Analysis","text":"<p> Project link</p>"},{"location":"projects/creations/sentimental_analysis/#overview","title":"Overview","text":"<p>Developed a sentiment analysis model to analyze customer feedback from airline tweets, classifying sentiments as positive, neutral, or negative.</p>"},{"location":"projects/creations/sentimental_analysis/#technologies-used","title":"Technologies Used","text":"<ul> <li>BERT for text classification</li> <li>Python (scikit-learn, transformers)</li> <li>Natural Language Processing</li> <li>Data Visualization (WordCloud)</li> </ul>"},{"location":"projects/creations/sentimental_analysis/#key-features","title":"Key Features","text":"<ul> <li>Pre-trained BERT model fine-tuning</li> <li>Multi-class sentiment classification</li> <li>Real-time sentiment prediction</li> <li>Interactive visualization dashboard</li> <li>Comparative model performance analysis</li> </ul>"},{"location":"projects/creations/sentimental_analysis/#results","title":"Results","text":"<ul> <li>Achieved 87% accuracy in sentiment classification</li> <li>Successfully identified key customer pain points</li> <li>Generated actionable insights for service improvement</li> </ul>"},{"location":"projects/creations/sentimental_analysis/#introduction","title":"Introduction","text":"<p>Note: Retraining the BERT model took a long time using a local computer, to run in the Google Colab will be a good choice</p>"},{"location":"projects/creations/sentimental_analysis/#objectives","title":"Objectives","text":"<p>To predict sentiment (postive, neutral, negeative) of customer feedback using tweet texts of differnt airline companies and compare different models\u2019performace on text classification.</p> <p>Specifically, multiple machine learing models such as KNN, Random forest and SVC have been used for conduct classification as a baseline. A new language representation model named BERT (Bidirectional Encoder Representations from Transformers) was also implemented to conduct sentiment analysis.</p>"},{"location":"projects/creations/sentimental_analysis/#bert","title":"BERT","text":"<p>Bidirectional Encoder Representations from Transformers (BERT) is a technique for NLP (Natural Language Processing) pre-training developed by Google and published in 2018.</p> <p>BERT is a method of pretraining language representations that was used to create models that NLP practicioners can then download and use for free. You can either use these models to extract high quality language features from your text data, or you can fine-tune these models on a specific task (classification, entity recognition, question answering, etc.) with your own data to produce state of the art predictions.</p>"},{"location":"projects/creations/sentimental_analysis/#how-bert-works","title":"How BERT works?","text":"<p>BERT was built on the Transformer, an attention mechanism that learns contextual relations between words (or sub-words) in a text. The attention mechanism was used to extratct information of context of a given words and then encode it in a learned vector. Generally, there are two mechanisms - an encoder that reads the text input and a decoder that produces a prediction for the task.</p> <p>The detailed workings of Transformer are described in a paper by Google. The figure below describe the brief steps of BERT during the traning process.</p> <p>where the model takes a pair of sequences and pools the representation of the first token in the sequence. Note that the original BERT model was trained for a masked language model and next-sentence prediction tasks, which includes layers for language model decoding and classification. These layers will not be used for fine-tuning the sentence pair classification.</p> <p>To help the model distinguish between the two sentences in training, the input is processed in the following way before entering the model:</p> <p>1 A [CLS] token is inserted at the beginning of the first sentence and a [SEP] token is inserted at the end of each sentence. 2 A sentence embedding indicating Sentence A or Sentence B is added to each token. Sentence embeddings are similar in concept to token embeddings with a vocabulary of 2. 3 A positional embedding is added to each token to indicate its position in the sequence. The concept and implementation of positional embedding are presented in the Transformer paper. Why BERT? 1 BERT offers an advantage over models like Word2Vec, because while each word has a fixed representation under Word2Vec regardless of the context within which the word appears, BERT produces word representations that are dynamically informed by the words around them.</p> <p>2 As opposed to directional models, which read the text input sequentially (left-to-right or right-to-left), the Transformer encoder reads the entire sequence of words at once. Therefore it is considered bidirectional, though it would be more accurate to say that it\u2019s non-directional. This characteristic allows the model to learn the context of a word based on all of its surroundings (left and right of the word).</p>"},{"location":"projects/creations/sentimental_analysis/#data","title":"Data","text":"<p>You can go to here to download the data used for the project.</p> <p>The deep learning and machine learning to conduct multi-class classification of text can be found here</p>"},{"location":"projects/creations/sentimental_analysis/#refereence","title":"Refereence","text":"<p>1 BERT Word Embeddings Tutorial</p> <p>2 BERT Explained: State of the art language model for NLP</p>"},{"location":"projects/creations/time_series_analysis/","title":"Time Series Analysis","text":""},{"location":"projects/creations/time_series_analysis/#overview","title":"Overview","text":"<p>Implemented advanced time series analysis models for forecasting and anomaly detection in business metrics.</p>"},{"location":"projects/creations/time_series_analysis/#technologies","title":"Technologies","text":"<ul> <li>ARIMA/SARIMA</li> <li>Prophet</li> <li>LSTM</li> <li>Statistical Methods</li> <li>Bayesian Analysis</li> </ul>"},{"location":"projects/creations/time_series_analysis/#key-features","title":"Key Features","text":"<ul> <li>Multi-step forecasting</li> <li>Seasonality detection</li> <li>Anomaly identification</li> <li>Trend analysis</li> <li>Uncertainty quantification</li> </ul>"},{"location":"projects/creations/time_series_analysis/#applications","title":"Applications","text":"<ul> <li>Sales forecasting</li> <li>Demand prediction</li> <li>Resource optimization</li> <li>Market trend analysis</li> </ul>"},{"location":"projects/creations/waveform_processing/","title":"Waveform Processing","text":""},{"location":"projects/creations/waveform_processing/#overview","title":"Overview","text":"<p>Advanced signal processing techniques for waveform data analysis and feature extraction.</p>"},{"location":"projects/creations/waveform_processing/#technologies","title":"Technologies","text":"<ul> <li>Signal Processing</li> <li>Python Scientific Stack</li> <li>Machine Learning</li> <li>Statistical Analysis</li> </ul>"},{"location":"projects/creations/waveform_processing/#key-features","title":"Key Features","text":"<ul> <li>Waveform decomposition</li> <li>Feature extraction</li> <li>Pattern recognition</li> <li>Noise reduction</li> <li>Real-time processing</li> </ul>"},{"location":"projects/creations/waveform_processing/#applications","title":"Applications","text":"<ul> <li>LiDAR data analysis</li> <li>Acoustic signal processing</li> <li>Sensor data analysis</li> <li>Pattern detection</li> </ul>"}]}